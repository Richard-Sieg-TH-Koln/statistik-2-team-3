{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from germansentiment import SentimentModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/processed/songs_complete_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "model.model.to(mps_device)\n",
    "model.device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, probabilities = model.predict_sentiment(dataset[\"lyrics\"][:10], output_probabilities = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(list(zip(classes, probabilities, dataset[\"lyrics\"][:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv(\"../data/processed/songs_complete_final.csv\")\n",
    "ds.dropna(subset=[\"genre_cat\"], inplace=True)\n",
    "ds[\"genre_cat\"].unique()\n",
    "factorized = pd.factorize(ds[\"genre_cat\"])\n",
    "print(factorized)\n",
    "ds[\"labels\"] = factorized[0]\n",
    "ds.to_csv(\"../data/processed/songs_complete_final_no_nan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "hf_dataset = load_dataset(\"csv\", data_files=\"../data/processed/songs_complete_final_no_nan.csv\")\n",
    "# hf_dataset=hf_dataset.rename_columns({\"genre_cat\": \"labels\"})\n",
    "print(hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = hf_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "train_ds = split[\"train\"]\n",
    "test_ds = split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"lyrics\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_ds.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = train_tokenized.shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = test_tokenized.shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {idx: val for idx, val in enumerate(factorized[1])}\n",
    "print(id2label)\n",
    "label2id = {val: key for (key, val) in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-german-cased\", num_labels=4, id2label=id2label, label2id=label2id)\n",
    "# model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert_genre\",\n",
    "    use_mps_device=True,\n",
    "    num_train_epochs=2,\n",
    "    # learning_rate=2e-5,\n",
    "    # per_device_train_batch_size=16,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    # weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuraracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    results = {}\n",
    "    results.update(accuraracy.compute(predictions=predictions, references=labels))\n",
    "    results.update(recall.compute(predictions=predictions, references=labels, average=\"micro\"))\n",
    "    results.update(precision.compute(predictions=predictions, references=labels, average=\"micro\"))\n",
    "    results.update(f1.compute(predictions=predictions, references=labels, average=\"micro\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True, device=\"mps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc1 = \"\"\"\n",
    "ch denke an das, was Du empfiehlst:\n",
    "\"Talent borrows, genius steals\"\n",
    "An das was Du mir anvertraust:\n",
    "\"Wähle dir deine fallen aus\"\n",
    "Ich glaub ich kanns erst jetzt verstehen\n",
    "Wir müssen durch den Spiegel gehen\n",
    "Danke auch für den Versuch\n",
    "Das hier ist kein Wörterbuch\n",
    "Du streichst mir über\n",
    "Mein Gesicht\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Meine Liebe\n",
    "Dein Verzicht\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Völker! Auf zum Gefecht!\n",
    "Die Illusion wird Menschenrecht\n",
    "Ich bin nicht allein in meiner Sucht\n",
    "Vor den Spießern auf der Flucht\n",
    "Du denkst an mich\n",
    "Ich denk' an Dich\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Unser Denken\n",
    "Verbündet sich\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Jeden Morgen, jede Nacht\n",
    "Jeden Morgen, jede Nacht\n",
    "Jeden Morgen, jede Nacht\n",
    "Jeden Morgen, jede Nacht\n",
    "Du streichst mir über\n",
    "Mein Gesicht\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Meine Liebe\n",
    "Dein Verzicht\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Du streichst mir über\n",
    "Mein Gesicht\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "Meine Liebe\n",
    "Dein Verzicht\n",
    "Gegen die Welt\n",
    "Gegen den Strich\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kool1 = \"\"\"Ich komm auf die Bühne leg Hand ans Mic\n",
    "Fang langsam an und demolier dich am Ende wie Van Damme\n",
    "Geh hol deine Gun dann, wärs fair\n",
    "Doch bis dahin ist das einzge was du gewinnst nur Land man\n",
    "Guck euer Gerede macht Müde wie der Sandmann\n",
    "Ob Türke, Russe oder der Rest von Grand Cannes\n",
    "Bei jedem finden diese Tracks Anklang, aber was ist das\n",
    "Deine Bitch hat ein Loch wie'n Schuss von ner Pumpgun\n",
    "Na dann viel Fun man, ich an deiner Stelle würd\n",
    "Sie am randstehen lassen wie'n Wandschrank\n",
    "Egal kein tam-tam, wahrt den Anstand meine\n",
    "Texte ficken alles wie Matrosen auf Landgang\n",
    "Für mich ist rappen wie wandern, s läuft\n",
    "Und ich bediene gerne euer Team alleine die Bank lang\n",
    "Danke an alle die mein Talent verkannt ham\n",
    "Heute seht ihr wohl alles anders wie in nem Handstand, oder nicht?\n",
    "Nie, niemals kriegt ihr mich weg, nie wi-ieder geh' ich\n",
    "Keiner von euch kann's, wie di-ieser Typ ist da Vinci\n",
    "Und das hier ist meine Mona-Lisa\n",
    "Des Original, die Eins, vielmals von ihm kopiert\n",
    "Aber niemals erreicht, ihr meint ihr seids\n",
    "Doch kommt nicht ran an Mona-Lisa\n",
    "Ich renn' durch Beats wie'n Athlet\n",
    "Ich nehm' Wörter und Silben und kann sie im Takt dreh'n\n",
    "Des ist'n Fetisch, ähnlich wie bei Leuten, die auf Leder und Lack stehen\n",
    "Ich kann mich an meinen Texten nicht satt sehen\n",
    "Ich hab' den übelsten dich-glatt-bügelnden Flow\n",
    "Alles, was ich rappe, muss \"Zack Zack Zack\" gehen\n",
    "Sie wollen mein Album mehr, als Miss Milian nackt sehen\n",
    "Feature mit dir, ich muss ablehnen\n",
    "Was geht, alle nenn'n dich Kackface\n",
    "Als würde dein Kopf unmittelbar hinter dem Sack kleben\n",
    "Mich will jeder wie 'ne Wiese plattmähen\n",
    "Mich battlen lass', wie bei 'nem Liebesakt blähen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(kool1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a1630c5465e12de1581cf816a14356e2922c5c54774098183d7941391ccb17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
