{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy Tutorial\n",
    "\n",
    "spaCy ist eine Python-Bibliothek für Natural Language Processing (NLP). Sie bietet eine Vielzahl von Funktionen, die für die Analyse von Texten nützlich sind. In diesem Tutorial werden wir uns mit den Grundlagen von spaCy vertraut machen und einige der Funktionen ausprobieren.\n",
    "\n",
    "spaCy besitzt sehr viele Funktionen unter anderem:\n",
    "- Tokenization\n",
    "- Text normalization, such as lowercasing, stemming/lemmatization\n",
    "- Part-of-speech tagging\n",
    "- Syntactic dependency parsing\n",
    "- Sentence boundary detection\n",
    "- Named entity recognition and annotation\n",
    "\n",
    "Außerdem kommen die Sprachpakete von spaCy mit einigen wichtigen Daten:\n",
    "- Large vocabulary, including stopword lists\n",
    "- Token \"probabilities\"\n",
    "- Word vectors\n",
    "\n",
    "spaCy ist mit Hilfe von Cython geschrieben und daher sehr schnell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Ich mag's, wenn sich die Wut entfacht\n",
    "Und ich mag deine Zaubermacht\n",
    "Ich mag die Tiere nachts im Wald\n",
    "Wenn sie flüstern, dass es schallt\n",
    "Ich mag den Weg, ich mag das Ziel\n",
    "Den Exzess, das Selbstexil\n",
    "Ich mag erschaudern und nicht zu knapp\n",
    "Ich gebe jedem etwas ab\n",
    "All das mag ich\n",
    "All das mag ich\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\n",
    "Ich mag die Wolken und den Wind\n",
    "Ich mag das Licht, das du mir bringst\n",
    "Wenn du dich um mich bemühst\n",
    "Wenn der Wahnsinn flammend grüßt\n",
    "Wenn die Träume Funken sprühen\n",
    "Und die weißen Blumen blühen\n",
    "Ich mag die Engel kurz vor dem Fall\n",
    "Diamanten aus dem All\n",
    "All das mag ich\n",
    "All das mag ich\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\n",
    "Ich mag die Spiegelung der Luft\n",
    "Und wenn die Sehnsucht nie verpufft\n",
    "Den Glanz des Lebens in einem Tag\n",
    "Ich mag den Zweifel, der an mir nagt\n",
    "Wenn meine Angst mich schnell verlässt\n",
    "Ich mag den Tanz, das Idiotenfest\n",
    "Wenn wir irren, nachts im Kreis\n",
    "Eine Bewegung gegen den Fleiß\n",
    "All das mag ich\n",
    "All das mag ich\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\n",
    "Aber hier leben, nein danke\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste von deutschen Sprachmodellen: https://spacy.io/models/de\n",
    "\n",
    "Wir laden das größte deutsche Sprachmodell (das keine dependency auf HuggingFace Transformer hat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wenden nun die spaCy pipeline auf den Text an und bekommen ein _Document_. Ein Document besteht unter anderem aus einer Liste an Tokens (tokenization), die wir in den nächsten Schritten analysieren.\n",
    "\n",
    "#### What is a Token?\n",
    "A token is a single chopped up element of the sentence, which could be a word or a group of words to analyse. The task of chopping the sentence up is called \"tokenisation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech tags\n",
    "\n",
    "#### What is a Speech Tag?\n",
    "A speech tag is a context sensitive description of what a word means in the context of the whole sentence.\n",
    "More information about the kinds of speech tags which are used in NLP can be [found here](http://www.winwaed.com/blog/2011/11/08/part-of-speech-tags/).\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. CARDINAL, Cardinal Number - 1,2,3\n",
    "2. PROPN, Proper Noun, Singular - \"Matic\", \"Andraz\", \"Cardiff\"\n",
    "3. INTJ, Interjection - \"Uhhhhhhhhhhh\"\n",
    "\n",
    "- Text: The original word text.\n",
    "- Lemma: The base form of the word.\n",
    "- POS: The simple UPOS part-of-speech tag.\n",
    "- Tag: The detailed part-of-speech tag.\n",
    "- Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "- Shape: The word shape – capitalization, punctuation, digits.\n",
    "- is alpha: Is the token an alpha character?\n",
    "- is stop: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Ich || pos: PRON || tag: PPER dep: sb || lemma: ich\n",
      "text: mag's || pos: AUX || tag: VVFIN dep: ROOT || lemma: mag's\n",
      "text: , || pos: PUNCT || tag: $, dep: punct || lemma: --\n",
      "text: wenn || pos: SCONJ || tag: KOUS dep: cp || lemma: wenn\n",
      "text: sich || pos: PRON || tag: PRF dep: oa || lemma: sich\n",
      "text: die || pos: DET || tag: ART dep: nk || lemma: der\n",
      "text: Wut || pos: NOUN || tag: NN dep: sb || lemma: Wut\n",
      "text: entfacht || pos: VERB || tag: VVPP dep: mo || lemma: entfachen\n",
      "text: \n",
      " || pos: SPACE || tag: _SP dep: dep || lemma: \n",
      "\n",
      "text: Und || pos: CCONJ || tag: KON dep: ju || lemma: und\n",
      "text: ich || pos: PRON || tag: PPER dep: sb || lemma: ich\n",
      "text: mag || pos: VERB || tag: VMFIN dep: ROOT || lemma: mögen\n",
      "text: deine || pos: DET || tag: PPOSAT dep: nk || lemma: dein\n",
      "text: Zaubermacht || pos: NOUN || tag: NN dep: oa || lemma: Zaubermacht\n",
      "text: \n",
      " || pos: SPACE || tag: _SP dep: dep || lemma: \n",
      "\n",
      "text: Ich || pos: PRON || tag: PPER dep: sb || lemma: ich\n",
      "text: mag || pos: AUX || tag: VMFIN dep: ROOT || lemma: mögen\n",
      "text: die || pos: DET || tag: ART dep: nk || lemma: der\n",
      "text: Tiere || pos: NOUN || tag: NN dep: oa || lemma: Tier\n",
      "text: nachts || pos: ADV || tag: ADV dep: mo || lemma: nachts\n",
      "text: im || pos: ADP || tag: APPRART dep: mo || lemma: in\n",
      "text: Wald || pos: NOUN || tag: NN dep: nk || lemma: Wald\n",
      "text: \n",
      " || pos: SPACE || tag: _SP dep: dep || lemma: \n",
      "\n",
      "text: Wenn || pos: SCONJ || tag: KOUS dep: cp || lemma: wenn\n",
      "text: sie || pos: PRON || tag: PPER dep: sb || lemma: sie\n",
      "text: flüstern || pos: VERB || tag: VVFIN dep: mo || lemma: flüstern\n",
      "text: , || pos: PUNCT || tag: $, dep: punct || lemma: --\n",
      "text: dass || pos: SCONJ || tag: KOUS dep: cp || lemma: dass\n",
      "text: es || pos: PRON || tag: PPER dep: sb || lemma: es\n",
      "text: schallt || pos: VERB || tag: VVFIN dep: oc || lemma: schallen\n",
      "text: \n",
      " || pos: SPACE || tag: _SP dep: dep || lemma: \n",
      "\n",
      "text: Ich || pos: PRON || tag: PPER dep: sb || lemma: ich\n",
      "text: mag || pos: VERB || tag: VMFIN dep: cj || lemma: mögen\n",
      "text: den || pos: DET || tag: ART dep: nk || lemma: der\n",
      "text: Weg || pos: NOUN || tag: NN dep: oa || lemma: Weg\n",
      "text: , || pos: PUNCT || tag: $, dep: punct || lemma: --\n",
      "text: ich || pos: PRON || tag: PPER dep: sb || lemma: ich\n",
      "text: mag || pos: AUX || tag: VMFIN dep: oc || lemma: mögen\n",
      "text: das || pos: DET || tag: ART dep: nk || lemma: der\n",
      "text: Ziel || pos: NOUN || tag: NN dep: oa || lemma: Ziel\n",
      "text: \n",
      " || pos: SPACE || tag: _SP dep: dep || lemma: \n",
      "\n",
      "text: Den || pos: DET || tag: ART dep: nk || lemma: der\n",
      "text: Exzess || pos: NOUN || tag: NN dep: cj || lemma: Exzess\n",
      "text: , || pos: PUNCT || tag: $, dep: punct || lemma: --\n",
      "text: das || pos: DET || tag: ART dep: nk || lemma: der\n",
      "text: Selbstexil || pos: NOUN || tag: NN dep: app || lemma: Selbstexil\n",
      "text: \n",
      " || pos: SPACE || tag: _SP dep: dep || lemma: \n",
      "\n",
      "text: Ich || pos: PRON || tag: PPER dep: sb || lemma: ich\n",
      "text: mag || pos: AUX || tag: VMFIN dep: cj || lemma: mögen\n",
      "text: erschaudern || pos: VERB || tag: VVINF dep: oc || lemma: erschaudern\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:10]:\n",
    "    print(f'text: {token.text} || pos: {token.pos_} || tag: {token.tag_} dep: {token.dep_} || lemma: {token.lemma_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are Stop Words?\n",
    "\n",
    "Stop words are the common words in a vocabulary which are of little value when considering word frequencies in text. This is because they don't provide much useful information about what the sentence is telling the reader.\n",
    "\n",
    "Example: _\"the\",\"and\",\"a\",\"are\",\"is\"_\n",
    "\n",
    "#### What is a Corpus?\n",
    "\n",
    "A corpus (plural: corpora) is a large collection of text or documents and can provide useful training data for NLP models. A corpus might be built from transcribed speech or a collection of manuscripts. Each item in a corpus is not necessarily unique and frequency counts of words can assist in uncovering the structure in a corpus.\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. Every word written in the complete works of Shakespeare\n",
    "2. Every word spoken on BBC Radio channels for the past 30 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ich', 'wenn', 'sich', 'die', 'Und', 'ich', 'mag', 'deine', 'Ich', 'mag']\n"
     ]
    }
   ],
   "source": [
    "# Get stop words\n",
    "stop_words = [token.text for token in doc if token.is_stop]\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns auch die Liste der Sätze holen. Dabei unterteilt spaCy nicht nur nach Interpunktion, sondern auch nach semantischen Eigenschaften. Gerade bei Songtexten funktioniert das aber nicht immer so gut, wie wir gleich sehen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mFailed to start the Kernel '.venv (Python 3.10.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Canceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Get sentences\n",
    "sentences = list(doc.sents)\n",
    "print(len(sentences))\n",
    "# Hier sehen wir auch schon ein Problem mit der Tokenisierung.\n",
    "print([token.text for token in sentences[3]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entities\n",
    "\n",
    "#### Named Entities\n",
    "\n",
    "A named entity is any real world object such as a person, location, organisation or product with a proper name. \n",
    "\n",
    "Example:\n",
    "\n",
    "\t1. Barack Obama\n",
    "\t2. Edinburgh\n",
    "\t3. Ferrari Enzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selbstexil\n",
      "Ich (MISC)\n",
      "Engel (PER)\n",
      "All\n",
      "All (MISC)\n",
      "Idiotenfest (PER)\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.text} ({ent.label_})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brack Obama (PER)\n",
      "USA (LOC)\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"Brack Obama war der 44. Präsident der USA.\")\n",
    "for ent in doc2.ents:\n",
    "    print(f'{ent.text} ({ent.label_})')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing\n",
    "\n",
    "#### What are syntactic dependencies?\n",
    "\n",
    "We have the speech tags and we have all of the tokens in a sentence, but how do we relate the two to uncover the syntax in a sentence? Syntactic dependencies describe how each type of word relates to each other in a sentence, this is important in NLP in order to extract structure and understand grammar in plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich mag's, wenn sich die Wut entfacht\n",
      "\n",
      "mag's\n",
      "[Ich, ,, entfacht]\n"
     ]
    }
   ],
   "source": [
    "sent = sentences[0]\n",
    "print(sent.text)\n",
    "print(sent.root)\n",
    "print(list(sent.root.children))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit displaCy können wir den dependency tree visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"e27ab59f68d94ad6bc9e00b21b529f8d-0\" class=\"displacy\" width=\"1450\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ich</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">mag's,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">wenn</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sich</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">die</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Wut</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">entfacht</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 1095.0,89.5 1095.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-5\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1100.0,2.0 1100.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,354.0 L1108.0,342.0 1092.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e27ab59f68d94ad6bc9e00b21b529f8d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1260.0,354.0 L1268.0,342.0 1252.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Und ich mag deine Zaubermacht</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sentences[1], style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding / Similarity\n",
    "\n",
    "#### What are Word embeddings?\n",
    "\n",
    "A word embedding is a representation of a word, and by extension a whole language corpus, in a vector or other form of numerical mapping. This allows words to be treated numerically with word similarity represented as spatial difference in the dimensions of the word embedding mapping.\n",
    "\n",
    "Example:\n",
    "\t\n",
    "With word embeddings we can understand that vector operations describe word similarity. This means that we can see vector proofs of statements such as:\n",
    "\n",
    "\tking-queen==man-woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6451995372772217\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(\"Ich mag Orangen und Birnen.\")\n",
    "orangen = doc3[2]\n",
    "birnen = doc3[4]\n",
    "print(orangen.similarity(birnen))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Pipelines sind eine Möglichkeit, spaCy mit verschiedenen Funktionen zu erweitern. Wenn wir ein Sprachpaket laden, bekommen wir eine Standard-Pipeline, die aus Tokenizer, Tagger, Parser, NER und Entity Linker besteht. Wir können diese Pipeline aber auch erweitern, indem wir weitere Funktionen hinzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x25160d11d00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytextrank\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "# https://derwen.ai/docs/ptr/\n",
    "nlp.add_pipe(\"textrank\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funken\n",
      "0.06960498892566462 1\n",
      "[Funken]\n",
      "All\n",
      "0.0681919105236853 1\n",
      "[All]\n",
      "Kreis\n",
      "0.05687523895429876 1\n",
      "[Kreis]\n",
      "Idiotenfest\n",
      "0.04853098558702389 1\n",
      "[Idiotenfest]\n",
      "Wald\n",
      "0.04693971377563045 1\n",
      "[Wald]\n",
      "Diamanten\n",
      "0.04428881417751234 1\n",
      "[Diamanten]\n",
      "Engel\n",
      "0.03451061082711543 1\n",
      "[Engel]\n",
      "den Fleiß\n",
      "0.029186060964137752 1\n",
      "[den Fleiß]\n",
      "die Träume\n",
      "0.029120810505937896 1\n",
      "[die Träume]\n",
      "das Selbstexil\n",
      "0.028291180429706193 1\n",
      "[das Selbstexil]\n",
      "Den Exzess\n",
      "0.027032795649409438 1\n",
      "[Den Exzess]\n",
      "die weißen Blumen\n",
      "0.02687071711994295 1\n",
      "[die weißen Blumen]\n",
      "den Zweifel\n",
      "0.02680582991934769 1\n",
      "[den Zweifel]\n",
      "der Wahnsinn\n",
      "0.026451344456483436 1\n",
      "[der Wahnsinn]\n",
      "das Ziel\n",
      "0.025326207184185347 1\n",
      "[das Ziel]\n",
      "einem Tag\n",
      "0.024843241373835395 1\n",
      "[einem Tag]\n",
      "den Weg\n",
      "0.02357745637165401 1\n",
      "[den Weg]\n",
      "dem All\n",
      "0.02317363922321631 1\n",
      "[dem All]\n",
      "des Lebens\n",
      "0.02317363922321631 1\n",
      "[des Lebens]\n",
      "das Idiotenfest\n",
      "0.022415502074164873 1\n",
      "[das Idiotenfest]\n",
      "der Luft\n",
      "0.02168052510723538 1\n",
      "[der Luft]\n",
      "Selbstexil\n",
      "Ich\n",
      "0.020544613246650238 1\n",
      "[Selbstexil\n",
      "Ich]\n",
      "Den Glanz\n",
      "0.020456127029980856 1\n",
      "[Den Glanz]\n",
      "das Licht\n",
      "0.020456127029980856 1\n",
      "[das Licht]\n",
      "deine Zaubermacht\n",
      "0.01978685248554706 1\n",
      "[deine Zaubermacht]\n",
      "den Tanz\n",
      "0.01978685248554706 1\n",
      "[den Tanz]\n",
      "dem Fall\n",
      "0.018057293999138718 1\n",
      "[dem Fall]\n",
      "den Wind\n",
      "0.018057293999138718 1\n",
      "[den Wind]\n",
      "All\n",
      "All\n",
      "0.016828334771725455 1\n",
      "[All\n",
      "All]\n",
      "die Engel\n",
      "0.015939768360746804 1\n",
      "[die Engel]\n",
      "die Sehnsucht\n",
      "0.015939768360746804 1\n",
      "[die Sehnsucht]\n",
      "die Spiegelung\n",
      "0.015939768360746804 1\n",
      "[die Spiegelung]\n",
      "die Tiere\n",
      "0.015939768360746804 1\n",
      "[die Tiere]\n",
      "die Wolken\n",
      "0.015939768360746804 1\n",
      "[die Wolken]\n",
      "die Wut\n",
      "0.015939768360746804 1\n",
      "[die Wut]\n",
      "meine Angst\n",
      "0.015939768360746804 1\n",
      "[meine Angst]\n",
      "All das\n",
      "0.0 3\n",
      "[All das, All das, All das]\n",
      "Ich\n",
      "0.0 11\n",
      "[Ich, Ich, Ich, Ich, Ich, Ich, Ich, Ich, Ich, Ich, Ich]\n",
      "das\n",
      "0.0 4\n",
      "[das, das, das, das]\n",
      "der\n",
      "0.0 1\n",
      "[der]\n",
      "dich\n",
      "0.0 1\n",
      "[dich]\n",
      "du\n",
      "0.0 2\n",
      "[du, du]\n",
      "es\n",
      "0.0 1\n",
      "[es]\n",
      "ich\n",
      "0.0 8\n",
      "[ich, ich, ich, ich, ich, ich, ich, ich]\n",
      "jedem\n",
      "0.0 1\n",
      "[jedem]\n",
      "mich\n",
      "0.0 2\n",
      "[mich, mich]\n",
      "mir\n",
      "0.0 2\n",
      "[mir, mir]\n",
      "sich\n",
      "0.0 1\n",
      "[sich]\n",
      "sie\n",
      "0.0 1\n",
      "[sie]\n",
      "wir\n",
      "0.0 1\n",
      "[wir]\n"
     ]
    }
   ],
   "source": [
    "# examine the top-ranked phrases in the document\n",
    "for phrase in doc._.phrases:\n",
    "    print(phrase.text)\n",
    "    print(phrase.rank, phrase.count)\n",
    "    print(phrase.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy_language_detection import LanguageDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\linhn\\github-classroom\\Richard-Sieg-TH-Koln\\statistik-2-team-3\\notebooks\\spacy-tutorial.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/linhn/github-classroom/Richard-Sieg-TH-Koln/statistik-2-team-3/notebooks/spacy-tutorial.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m LanguageDetector(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)  \u001b[39m# We use the seed 42\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/linhn/github-classroom/Richard-Sieg-TH-Koln/statistik-2-team-3/notebooks/spacy-tutorial.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Language\u001b[39m.\u001b[39mfactory(\u001b[39m\"\u001b[39m\u001b[39mlanguage_detector\u001b[39m\u001b[39m\"\u001b[39m, func\u001b[39m=\u001b[39mget_lang_detector)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/linhn/github-classroom/Richard-Sieg-TH-Koln/statistik-2-team-3/notebooks/spacy-tutorial.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m'\u001b[39m\u001b[39mlanguage_detector\u001b[39m\u001b[39m'\u001b[39m, last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector(seed=42)  # We use the seed 42\n",
    "\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'de', 'score': 0.9999962758266624}\n",
      "{'language': 'de', 'score': 0.9999968689008363}\n",
      "{'language': 'de', 'score': 0.9999972447608682}\n",
      "{'language': 'de', 'score': 0.9999966630732081}\n",
      "{'language': 'de', 'score': 0.9999960900081715}\n",
      "{'language': 'de', 'score': 0.9999961437337193}\n",
      "{'language': 'de', 'score': 0.9999959487828781}\n",
      "{'language': 'de', 'score': 0.9999957419936483}\n",
      "{'language': 'de', 'score': 0.999996150605792}\n",
      "{'language': 'de', 'score': 0.9999959818918926}\n",
      "{'language': 'de', 'score': 0.9999945277750815}\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    \n",
    "    print(sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mFailed to start the Kernel '.venv (Python 3.10.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Canceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "**Das profanity Paket ist archived und unterstützt nicht mehr spaCy 3...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.to_disk(\"custom_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a1630c5465e12de1581cf816a14356e2922c5c54774098183d7941391ccb17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
